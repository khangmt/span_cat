title: "My ner project"
description: "Train a ner model on the `dataset` defined in `project.yml`"
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  config: "config" # config_tok2vec, config_trf
  dataset: "mitrea_ttack" # healthsea, toxic, genia

  train: "train"
  dev: "dev"

  gpu_id: 0
  eval_split: 0.25

  ner_model: "training/ner/${vars.dataset}/${vars.config}/model-best"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "training", "configs", "scripts", "data", "metrics"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that all required files are available.
assets:
  - dest: "assets/data.csv"
    description: "Annotations from the Healthsea dataset"
    url: ""

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  preprocess:
    - preprocess_data
  ner:
    - train_ner
    - evaluate_ner

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "install"
    help: "Install requirements"
    script:
      - "pip install -r requirements.txt"

  - name: "preprocess_data"
    help: "Format my data annotations into .spaCy training format"
    script:
      - "python scripts/preprocessing/preprocess.py assets/data.csv data/${vars.dataset}_${vars.train}.spacy data/${vars.dataset}_${vars.dev}.spacy ${vars.eval_split}"
    deps:
      - "assets/data.csv"
      - "scripts/preprocessing/preprocess.py"
    outputs:
      - "data/${vars.dataset}_${vars.train}.spacy"
      - "data/${vars.dataset}_${vars.dev}.spacy"


  - name: "train_ner"
    help: "Train a ner model on the `dataset` defined in `project.yml`"
    script:
      - "python -m spacy train configs/${vars.suggester}/${vars.config}.cfg --output training/ner/${vars.dataset}/${vars.config}/ --paths.train data/${vars.dataset}_${vars.train}.spacy --paths.dev data/${vars.dataset}_${vars.dev}.spacy --gpu-id ${vars.gpu_id}"
    deps:
      - "configs/${vars.suggester}/${vars.config}.cfg"
      - "data/${vars.dataset}_${vars.train}.spacy"
      - "data/${vars.dataset}_${vars.dev}.spacy"
    outputs:
      - "${vars.ner_model}"

  - name: "evaluate_ner"
    help: "Evaluate a trained ner model  on the `dataset` defined in `project.yml`"
    script:
      - "python -m spacy evaluate ${vars.ner_model} data/${vars.dataset}_${vars.dev}.spacy --output metrics/ner_${vars.dataset}_${vars.config}.json --gpu-id ${vars.gpu_id}"
    deps:
      - "${vars.ner_model}"
      - "data/${vars.dataset}_${vars.dev}.spacy"
    outputs:
      - metrics/ner_${vars.dataset}_${vars.config}.json

  - name: "reset"
    help: "Reset the project to its original state and delete all training process"
    script:
      - "python scripts/reset.py training"
      - "python scripts/reset.py metrics"
      - "python scripts/reset.py assets"
      - "python scripts/reset.py data"